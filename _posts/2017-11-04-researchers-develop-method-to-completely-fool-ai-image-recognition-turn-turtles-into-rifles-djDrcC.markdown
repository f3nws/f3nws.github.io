---
layout: post
title:  "Researchers develop method to completely fool AI image recognition, turn turtles into rifles"
date: 2017-11-04 02:01:37Z
categories: bgr
---

![Researchers develop method to completely fool AI image recognition, turn turtles into rifles](https://boygeniusreport.files.wordpress.com/2017/11/screen-shot-2017-11-03-at-11-21-56-am.png)

Advancements in AI are happening at a breakneck pace, and they have been for some time now, but computers aren't infallible. Some very interesting new research into AI image recognition has revealed a stunning vulnerability that will make you think twice the next time someone tells you computer algorithms are outpacing human intelligence. The research team, which is comprised for MIT grad students and undergrads from the student-run LabSix group, were able to create 3D objects that look perfectly identifiable to human eyes, but completely confuse AI object recognition software. The team's "3D adversarial objects" throw the object recognition algorithms for a loop, making the computers think they're looking at something they're really not, and it's honestly incredible. https://www.youtube.com/watch?time_continue=42&v=piYnd_wYlT8 The team used 3D objects which were already easily identifiable by the AI, including a small model of a turtle, for example, and then modified them in an effort to trick the computer. The result was a turtle model that looks very similar to the initial, unmodified version, but is identified as a "rifle" or "assault rifle" by the AI. What's even more impressive is that the turtle doesn't look all that much different from the default version, but the AI shows remarkable confidence that it's actually a firearm of some type. “This work clearly shows that something is broken with how neural networks work, and that researchers who develop these systems need to be spending a lot more time thinking about defending against these sorts of so-called ‘adversarial examples,’” one of the lead authors of the paper, and PhD candidate, Anish Athalye explains. “If we want safe self-driving cars and other systems that use neural networks, this is an area of research that needs to be the focus of much more study.” So why does this matter? We as a society are only just starting to test the kinds of things that are made possible thanks to AI advancements, and object recognition is still in its infancy in that regard. In the future, something like a securi...


Full story on F3News: [Researchers develop method to completely fool AI image recognition, turn turtles into rifles](http://www.f3nws.com/n/djDrcC)

> Posted on: Saturday, November 4, 2017 2:01:37 AM
